{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Libraries\n"
      ],
      "metadata": {
        "id": "rCubbq8RWE6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "lRW_PHBoT6rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation using Tensor Flow"
      ],
      "metadata": {
        "id": "d48Kju3mWJa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_logic_gate_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(1, activation='sigmoid', input_shape=(2,))\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "65Yrk4baUJER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation Manualy"
      ],
      "metadata": {
        "id": "uxrXFmzaWPY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def train_manual_logic_gate(X, y, epochs=1000, lr=0.1):\n",
        "    weights = np.random.randn(2, 1)\n",
        "    bias = np.random.randn(1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        z = np.dot(X, weights) + bias\n",
        "        y_pred = sigmoid(z)\n",
        "\n",
        "        error = y_pred - y\n",
        "        dw = np.dot(X.T, error * y_pred * (1 - y_pred))\n",
        "        db = np.sum(error * y_pred * (1 - y_pred))\n",
        "\n",
        "        weights -= lr * dw\n",
        "        bias -= lr * db\n",
        "\n",
        "    return weights, bias"
      ],
      "metadata": {
        "id": "l_4HST-cU3gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AND Gate"
      ],
      "metadata": {
        "id": "kZlOEb-1UcAW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4eheWqdSJ89",
        "outputId": "a8ace6b9-8c2b-40b8-db52-c51b478e6e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Weights: [[2.67492362]\n",
            " [2.69840245]] Bias: [-4.15400706]\n"
          ]
        }
      ],
      "source": [
        "# Training Data\n",
        "X_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_train_and = np.array([[0], [0], [0], [1]])\n",
        "\n",
        "# Training Model\n",
        "and_model = build_logic_gate_model()\n",
        "and_model.fit(X_train, y_train_and, epochs=100, verbose=0)\n",
        "\n",
        "# Training Manual Model\n",
        "weights, bias = train_manual_logic_gate(X_train, y_train_and)\n",
        "print(\"Trained Weights:\", weights, \"Bias:\", bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR Gate"
      ],
      "metadata": {
        "id": "JGWlI5wzV97G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "X_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_train_or = np.array([[0], [1], [1], [1]])\n",
        "\n",
        "# Training Model\n",
        "or_model = build_logic_gate_model()\n",
        "or_model.fit(X_train, y_train_or, epochs=100, verbose=0)\n",
        "\n",
        "# Training Manual Model\n",
        "weights, bias = train_manual_logic_gate(X_train, y_train_or)\n",
        "print(\"Trained Weights:\", weights, \"Bias:\", bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_GiKQViSPi8",
        "outputId": "06544839-476c-4d63-a10f-43fa12b64185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Weights: [[3.32425451]\n",
            " [3.32860921]] Bias: [-1.35494321]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAND Gate\n"
      ],
      "metadata": {
        "id": "AoSniZVpV6da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "X_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_train_nand = np.array([[1], [1], [1], [0]])\n",
        "\n",
        "# Training Model\n",
        "nand_model = build_logic_gate_model()\n",
        "nand_model.fit(X_train, y_train_nand, epochs=100, verbose=0)\n",
        "\n",
        "# Training Manual Model\n",
        "weights, bias = train_manual_logic_gate(X_train, y_train_nand)\n",
        "print(\"Trained Weights:\", weights, \"Bias:\", bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01R9iTwSSraU",
        "outputId": "e6f0ac81-6c0b-44bb-ab79-e7668111edaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Weights: [[-2.61790911]\n",
            " [-2.61488265]] Bias: [4.05035557]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOR Gate"
      ],
      "metadata": {
        "id": "TCDkDNyWV4AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "X_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_train_nor = np.array([[1], [0], [0], [0]])\n",
        "\n",
        "# Training Model\n",
        "nor_model = build_logic_gate_model()\n",
        "nor_model.fit(X_train, y_train_nor, epochs=100, verbose=0)\n",
        "\n",
        "# Training Manual Model\n",
        "weights, bias = train_manual_logic_gate(X_train, y_train_nor)\n",
        "print(\"Trained Weights:\", weights, \"Bias:\", bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_eYbdfGS6ne",
        "outputId": "a551a5f5-d146-49ce-db3e-44534f20219c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Weights: [[-3.41248554]\n",
            " [-3.40393095]] Bias: [1.3994914]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XOR Gate"
      ],
      "metadata": {
        "id": "oGRNDCf8V1sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "X_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_train_xor = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Training Model\n",
        "xor_model = build_logic_gate_model()\n",
        "xor_model.fit(X_train, y_train_xor, epochs=1000, verbose=0)\n",
        "\n",
        "# Manual Neural Network\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def train_manual_xor_gate(X, y, epochs=10000, lr=0.1):\n",
        "    weights1 = np.random.randn(2, 2)\n",
        "    bias1 = np.random.randn(2)\n",
        "    weights2 = np.random.randn(2, 1)\n",
        "    bias2 = np.random.randn(1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        z1 = np.dot(X, weights1) + bias1\n",
        "        a1 = sigmoid(z1)\n",
        "        z2 = np.dot(a1, weights2) + bias2\n",
        "        a2 = sigmoid(z2)\n",
        "\n",
        "        # Backpropagation\n",
        "        error = a2 - y\n",
        "        dz2 = error * a2 * (1 - a2)\n",
        "        dw2 = np.dot(a1.T, dz2)\n",
        "        db2 = np.sum(dz2, axis=0)\n",
        "\n",
        "        dz1 = np.dot(dz2, weights2.T) * a1 * (1 - a1)\n",
        "        dw1 = np.dot(X.T, dz1)\n",
        "        db1 = np.sum(dz1, axis=0)\n",
        "\n",
        "        # Gradient update\n",
        "        weights1 -= lr * dw1\n",
        "        bias1 -= lr * db1\n",
        "        weights2 -= lr * dw2\n",
        "        bias2 -= lr * db2\n",
        "\n",
        "    return weights1, bias1, weights2, bias2\n",
        "\n",
        "# Training Manual Model\n",
        "weights1, bias1, weights2, bias2 = train_manual_xor_gate(X_train, y_train_xor)\n",
        "print(\"Trained Weights:\", weights1, weights2, \"Biases:\", bias1, bias2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URhYf-a8THFW",
        "outputId": "c75b69bd-2ac8-4514-c385-e4d744310fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Weights: [[ 3.66772759 -3.16417407]\n",
            " [ 6.68684066  6.69827399]] [[ 5.2755157 ]\n",
            " [-4.79524741]] Biases: [-0.66842035  2.37348536] [-0.47970182]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XNOR Gate"
      ],
      "metadata": {
        "id": "t_g0c1I_Vyba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "X_train = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_train_xnor = np.array([[1], [0], [0], [1]])\n",
        "\n",
        "# Training Model\n",
        "xnor_model = build_logic_gate_model()\n",
        "xnor_model.fit(X_train, y_train_xnor, epochs=1000, verbose=0)\n",
        "\n",
        "# Manual Neural Network\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def train_manual_xnor_gate(X, y, epochs=10000, lr=0.1):\n",
        "    weights1 = np.random.randn(2, 2)\n",
        "    bias1 = np.random.randn(2)\n",
        "    weights2 = np.random.randn(2, 1)\n",
        "    bias2 = np.random.randn(1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        z1 = np.dot(X, weights1) + bias1\n",
        "        a1 = sigmoid(z1)\n",
        "        z2 = np.dot(a1, weights2) + bias2\n",
        "        a2 = sigmoid(z2)\n",
        "\n",
        "        # Backpropagation\n",
        "        error = a2 - y\n",
        "        dz2 = error * a2 * (1 - a2)\n",
        "        dw2 = np.dot(a1.T, dz2)\n",
        "        db2 = np.sum(dz2, axis=0)\n",
        "\n",
        "        dz1 = np.dot(dz2, weights2.T) * a1 * (1 - a1)\n",
        "        dw1 = np.dot(X.T, dz1)\n",
        "        db1 = np.sum(dz1, axis=0)\n",
        "\n",
        "        # Gradient update\n",
        "        weights1 -= lr * dw1\n",
        "        bias1 -= lr * db1\n",
        "        weights2 -= lr * dw2\n",
        "        bias2 -= lr * db2\n",
        "\n",
        "    return weights1, bias1, weights2, bias2\n",
        "\n",
        "# Training Manual Model\n",
        "weights1, bias1, weights2, bias2 = train_manual_xnor_gate(X_train, y_train_xnor)\n",
        "print(\"Trained Weights:\", weights1, weights2, \"Biases:\", bias1, bias2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX9Yc-pITRW-",
        "outputId": "fdacdc5e-5213-4732-ae57-28484ef25c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Weights: [[6.10025537 3.61080751]\n",
            " [5.97476182 3.59171441]] [[-7.49246063]\n",
            " [ 8.12206618]] Biases: [-2.45538301 -5.48826735] [3.36319811]\n"
          ]
        }
      ]
    }
  ]
}